{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(\"/workspace/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/Call-for-Code/Spot-Challenge-Wildfires/main/data/Jan_30-with_historical_weather_forecasts_refreshed_again_on Jan_31.zip\"\n",
    "zip = zipfile.ZipFile(\"Jan_30-with_historical_weather_forecasts_refreshed_again_on Jan_31.zip\")\n",
    "zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"Jan_30\"\n",
    "file_wildfires = f\"{main_path}/Historical_Wildfires.csv\"\n",
    "wildfires_df = pd.read_csv(file_wildfires)\n",
    "wildfires_df[\"Date\"] = pd.to_datetime(wildfires_df[\"Date\"])\n",
    "wildfires_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wildfires_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_weather = f\"{main_path}/HistoricalWeather.csv\"\n",
    "weather_df = pd.read_csv(file_weather)\n",
    "\n",
    "# rename columns\n",
    "weather_df = weather_df.rename(\n",
    "    columns={\n",
    "        \"count()[unit: km^2]\": \"Area\",\n",
    "        \"min()\": \"Min\",\n",
    "        \"max()\": \"Max\",\n",
    "        \"mean()\": \"Mean\",\n",
    "        \"variance()\": \"Variance\",\n",
    "    }\n",
    ")\n",
    "\n",
    "weather_df[\"Date\"] = pd.to_datetime(weather_df[\"Date\"])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the data\n",
    "df_pivot = weather_df.pivot_table(\n",
    "    values=[\"Min\", \"Max\", \"Mean\", \"Variance\"],\n",
    "    index=[\"Date\", \"Region\"],\n",
    "    columns=[\"Parameter\"],\n",
    ")\n",
    "# Reset dataframe index\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Renaming Column names\n",
    "df_pivot.columns = [\n",
    "    col[0] if not (col[1]) else \"{1}_{0}\".format(*col)\n",
    "    for col in df_pivot.columns.values\n",
    "]\n",
    "\n",
    "# Rearranging Data and column\n",
    "params = df_pivot.columns.tolist()[3:]\n",
    "params.sort()\n",
    "weather_data = df_pivot[df_pivot.columns.tolist()[:3] + params].copy()\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_wildfires = f\"{main_path}/VegetationIndex.csv\"\n",
    "ndvi_df = pd.read_csv(file_wildfires)\n",
    "\n",
    "# convert to datetime format\n",
    "ndvi_df[\"Date\"] = pd.to_datetime(ndvi_df[\"Date\"])\n",
    "\n",
    "print(ndvi_df.dtypes)\n",
    "ndvi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_forecasts = f\"{main_path}/HistoricalWeatherForecasts.csv\"\n",
    "forecasts_df = pd.read_csv(file_forecasts)\n",
    "forecasts_df[\"Date\"] = pd.to_datetime(forecasts_df[\"Date\"])\n",
    "\n",
    "forecasts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge historical fire and weather data into one DataFrame\n",
    "df_all = wildfires_df.merge(weather_data, how=\"left\", on=[\"Date\", \"Region\"])\n",
    "df_all.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.corr()[\"Estimated_fire_area\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"dataset.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_all.merge(ndvi_df, how=\"inner\", on=[\"Date\", \"Region\"])\n",
    "df_temp.describe().transpose()\n",
    "df_temp.to_csv(\"dataset1.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_all.drop(\n",
    "    [\n",
    "        \"Region\",\n",
    "        \"Date\",\n",
    "        \"Mean_confidence\",\n",
    "        \"Std_confidence\",\n",
    "        \"Var_confidence\",\n",
    "        \"Count\",\n",
    "        \"Replaced\",\n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(df_corr.corr(), cmap=\"coolwarm\", annot=True, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = df_all[df_all[\"Region\"] == \"NSW\"].copy()\n",
    "df_all2.drop_duplicates(inplace=True)\n",
    "df_all2.reset_index(drop=True, inplace=True)\n",
    "df_all2 = df_all2.dropna(how=\"any\")\n",
    "df_all2 = df_all2.drop(\n",
    "    [\n",
    "        \"Date\",\n",
    "        \"Region\",\n",
    "        \"Mean_confidence\",\n",
    "        \"Std_confidence\",\n",
    "        \"Var_confidence\",\n",
    "        \"Count\",\n",
    "        \"Replaced\",\n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
